{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854c645f-a14b-49ca-a9f5-cb49de30006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "import laspy\n",
    "\n",
    "\n",
    "import time\n",
    "import requests\n",
    "                    \n",
    "from dask.distributed import LocalCluster, SSHCluster \n",
    "from laserfarm import Retiler, DataProcessing, GeotiffWriter, MacroPipeline\n",
    "from laserfarm.remote_utils import get_wdclient, get_info_remote, list_remote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32a2c7-6bc3-4a23-a7f3-be6163358654",
   "metadata": {},
   "source": [
    "## Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe9bea7-2750-4882-9dc5-5e4b4adbf273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "                    \n",
    "from dask.distributed import LocalCluster, SSHCluster \n",
    "from laserfarm import Retiler, DataProcessing, GeotiffWriter, MacroPipeline\n",
    "from laserfarm.remote_utils import get_wdclient, get_info_remote, list_remote\n",
    "\n",
    "param_remote_path_root = '/webdav'\n",
    "conf_remote_path_split = pathlib.Path(param_remote_path_root + '/split')\n",
    "conf_remote_path_retiled = pathlib.Path(param_remote_path_root + '/retiled/')\n",
    "conf_remote_path_norm = pathlib.Path(param_remote_path_root + '/norm/')\n",
    "conf_remote_path_targets = pathlib.Path(param_remote_path_root + '/targets')\n",
    "conf_local_tmp = pathlib.Path('/tmp')\n",
    "param_remote_path_ahn = param_remote_path_root + '/ahn'\n",
    "\n",
    "\n",
    "param_hostname = ''\n",
    "param_login = ''\n",
    "param_password = ''\n",
    "\n",
    "param_feature_name = 'perc_95_normalized_height'\n",
    "param_validate_precision = '0.001'\n",
    "param_tile_mesh_size = '10.'\n",
    "param_filter_type= 'select_equal'\n",
    "param_attribute = 'raw_classification'\n",
    "param_min_x = '-113107.81'\n",
    "param_max_x = '398892.19'\n",
    "param_min_y = '214783.87'\n",
    "param_max_y = '726783.87'\n",
    "param_n_tiles_side = '512'\n",
    "param_apply_filter_value = '1'\n",
    "param_laz_compression_factor = '7'\n",
    "param_max_filesize = '262144000'  # desired max file size (in bytes)\n",
    "\n",
    "conf_wd_opts = { 'webdav_hostname': param_hostname, 'webdav_login': param_login, 'webdav_password': param_password}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70913967-81e0-4b22-8b4d-aa1b3f5f2707",
   "metadata": {},
   "source": [
    "## Fetching Laz Files from remote WebDAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c8f77b-e28a-4b3b-aa29-5b18619251a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Laz Files 01-06-22\n",
    "laz_files = [f for f in list_remote(get_wdclient(conf_wd_opts), pathlib.Path(param_remote_path_ahn).as_posix())\n",
    "             if f.lower().endswith('.laz')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a0973e-42e3-47c9-9382-8e30f2086771",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Splitting big files into smaller files before retiling\n",
    "This step can be added if the original files are too large for normal VMs to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c935cbc-02b1-4f0a-a616-c2258a19931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split big files 01-60-22\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def save_chunk_to_laz_file(in_filename, \n",
    "                           out_filename, \n",
    "                           offset, \n",
    "                           n_points):\n",
    "    \"\"\"Read points from a LAS/LAZ file and write them to a new file.\"\"\"\n",
    "    \n",
    "    points = np.array([])\n",
    "    \n",
    "    with laspy.open(in_filename) as in_file:\n",
    "        with laspy.open(out_filename, \n",
    "                        mode=\"w\", \n",
    "                        header=in_file.header) as out_file:\n",
    "            in_file.seek(offset)\n",
    "            points = in_file.read_points(n_points)\n",
    "            out_file.write_points(points)\n",
    "    return len(points)\n",
    "\n",
    "def split_strategy(filename, max_filesize):\n",
    "    \"\"\"Set up splitting strategy for a LAS/LAZ file.\"\"\"\n",
    "    with laspy.open(filename) as f:\n",
    "        bytes_per_point = (\n",
    "            f.header.point_format.num_standard_bytes +\n",
    "            f.header.point_format.num_extra_bytes\n",
    "        )\n",
    "        n_points = f.header.point_count\n",
    "    n_points_target = int(\n",
    "        max_filesize * int(param_laz_compression_factor) / bytes_per_point\n",
    "    )\n",
    "    stem, ext = os.path.splitext(filename)\n",
    "    return [\n",
    "        (filename, f\"{stem}-{n}{ext}\", offset, n_points_target)\n",
    "        for n, offset in enumerate(range(0, n_points, n_points_target))\n",
    "    ]\n",
    "\n",
    "from webdav3.client import Client\n",
    "\n",
    "client = Client(conf_wd_opts)\n",
    "client.mkdir(conf_remote_path_split.as_posix())\n",
    "\n",
    "\n",
    "remote_path_split = conf_remote_path_split\n",
    "\n",
    "file = laz_files\n",
    "# for file in laz_files:\n",
    "client.download_sync(remote_path=os.path.join(param_remote_path_ahn,file), local_path=file)\n",
    "inps = split_strategy(file, int(param_max_filesize))\n",
    "for inp in inps:\n",
    "    save_chunk_to_laz_file(*inp)\n",
    "client.upload_sync(remote_path=os.path.join(conf_remote_path_split,file), local_path=file)\n",
    "\n",
    "for f in os.listdir('.'):\n",
    "    if not f.endswith('.LAZ'):\n",
    "        continue\n",
    "    os.remove(os.path.join('.', f))\n",
    "    \n",
    "split_laz_files = laz_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad5d0f-2cbb-4889-ae63-3972626db753",
   "metadata": {},
   "source": [
    "## Retiling of big files into smaller tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034685db-0dda-48f9-98f3-fd38ae2525ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 16:04:32,358 -           laserfarm.pipeline_remote_data -       INFO - Input dir set to /tmp/C_18HZ2.LAZ_input\n",
      "2022-06-21 16:04:32,359 -           laserfarm.pipeline_remote_data -       INFO - Output dir set to /tmp/C_18HZ2.LAZ_output\n",
      "2022-06-21 16:04:32,360 -           laserfarm.pipeline_remote_data -       INFO - Pulling from WebDAV /webdav/split/C_18HZ2.LAZ ...\n",
      "2022-06-21 16:04:33,582 -           laserfarm.pipeline_remote_data -       INFO - ... pulling completed.\n",
      "2022-06-21 16:04:33,584 -                        laserfarm.retiler -       INFO - Setting up the target grid\n",
      "2022-06-21 16:04:33,586 -                        laserfarm.retiler -       INFO - Splitting file /tmp/C_18HZ2.LAZ_input/C_18HZ2.LAZ with PDAL ...\n",
      "2022-06-21 16:04:34,098 -                        laserfarm.retiler -       INFO - ... splitting completed.\n",
      "2022-06-21 16:04:34,101 -                        laserfarm.retiler -       INFO - Redistributing files to tiles ...\n",
      "2022-06-21 16:04:34,105 -                        laserfarm.retiler -       INFO - ... file C_18HZ2_1.LAZ to tile_213_285\n",
      "2022-06-21 16:04:34,110 -                        laserfarm.retiler -       INFO - ... file C_18HZ2_2.LAZ to tile_212_285\n",
      "2022-06-21 16:04:34,111 -                        laserfarm.retiler -       INFO - ... redistributing completed.\n",
      "2022-06-21 16:04:34,113 -                        laserfarm.retiler -       INFO - Validating split ...\n",
      "2022-06-21 16:04:34,115 -                        laserfarm.retiler -       INFO - ... 257128 points in parent file\n",
      "2022-06-21 16:04:34,118 -                        laserfarm.retiler -       INFO - ... 231714 points in C_18HZ2_1.LAZ\n",
      "2022-06-21 16:04:34,120 -                        laserfarm.retiler -       INFO - ... 25414 points in C_18HZ2_2.LAZ\n",
      "2022-06-21 16:04:34,121 -                        laserfarm.retiler -       INFO - ... split validation completed.\n",
      "2022-06-21 16:04:34,122 -           laserfarm.pipeline_remote_data -       INFO - Pushing to WebDAV /webdav/retiled ...\n",
      "2022-06-21 16:04:39,018 -           laserfarm.pipeline_remote_data -       INFO - ... pushing completed.\n",
      "2022-06-21 16:04:39,020 -           laserfarm.pipeline_remote_data -       INFO - Removing input and output folders\n"
     ]
    }
   ],
   "source": [
    "# Retiling\n",
    "remote_path_retiled = str(conf_remote_path_retiled)\n",
    "\n",
    "grid_retile = {\n",
    "    'min_x': float(param_min_x),\n",
    "    'max_x': float(param_max_x),\n",
    "    'min_y': float(param_min_y),\n",
    "    'max_y': float(param_max_y),\n",
    "    'n_tiles_side': int(param_n_tiles_side)\n",
    "}\n",
    "\n",
    "retiling_input = {\n",
    "    'setup_local_fs': {'tmp_folder': conf_local_tmp.as_posix()},\n",
    "    'pullremote': conf_remote_path_split.as_posix(),\n",
    "    'set_grid': grid_retile,\n",
    "    'split_and_redistribute': {},\n",
    "    'validate': {},\n",
    "    'pushremote': conf_remote_path_retiled.as_posix(),\n",
    "    'cleanlocalfs': {}\n",
    "}\n",
    "\n",
    "# try:\n",
    "#     get_ipython\n",
    "#     file = laz_files[0]\n",
    "# except:\n",
    "#     file = laz_files\n",
    "    \n",
    "# for file in laz_files:\n",
    "file = split_laz_files\n",
    "retiler = Retiler(file.replace('\"',''),label=file).config(retiling_input).setup_webdav_client(conf_wd_opts)\n",
    "retiler_output = retiler.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb76ea-4dfe-4fe1-8533-b88df6e19ef0",
   "metadata": {},
   "source": [
    "## Fetching retilied files (tiles) from remote WebDAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9598142-9943-4bc2-aeae-d0661c5342d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Tiles\n",
    "remote_path_retiled\n",
    "tiles = [t.strip('/') for t in list_remote(get_wdclient(conf_wd_opts), conf_remote_path_retiled.as_posix())\n",
    "         if fnmatch.fnmatch(t, 'tile_*_*/')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4fae4-dad1-4a0f-b606-f8ec2563a2f9",
   "metadata": {},
   "source": [
    "## Normalization - normalize all the point cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670a06f-1a41-4909-9a0b-e88c8326a17f",
   "metadata": {},
   "source": [
    "This step is added as the previous notebook did not include this step. The two cells below are the original code deployed on SURF using macroPipline function, so it needs to be modified in order to be containerized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32537f33-f563-4b29-aeb4-507e97588952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 16:05:06,064 -           laserfarm.pipeline_remote_data -       INFO - Input dir set to /tmp/tile_278_391_input\n",
      "2022-06-21 16:05:06,065 -           laserfarm.pipeline_remote_data -       INFO - Output dir set to /tmp/tile_278_391_output\n",
      "2022-06-21 16:05:06,067 -           laserfarm.pipeline_remote_data -       INFO - Pulling from WebDAV /webdav/retiled/tile_278_391 ...\n",
      "2022-06-21 16:05:08,736 -           laserfarm.pipeline_remote_data -       INFO - ... pulling completed.\n",
      "2022-06-21 16:05:08,737 -                laserfarm.data_processing -       INFO - Loading point cloud data ...\n",
      "2022-06-21 16:05:08,738 -                laserfarm.data_processing -       INFO - ... loading /tmp/tile_278_391_input/tile_278_391/C_01GN2_1.LAZ\n",
      "2022-06-21 16:05:09,829 -                laserfarm.data_processing -       INFO - ... loading completed.\n",
      "2022-06-21 16:05:09,830 -                laserfarm.data_processing -       INFO - Normalizing point-cloud heights ...\n",
      "2022-06-21 16:05:10,678 -                                     root -       INFO - Cylinder size in Bytes: 3056136558.191318\n",
      "2022-06-21 16:05:10,680 -                                     root -       INFO - Memory size in Bytes: 16819240960\n",
      "2022-06-21 16:05:10,680 -                                     root -       INFO - Start tree creation\n",
      "2022-06-21 16:05:11,145 -                                     root -       INFO - Done with env tree creation\n",
      "2022-06-21 16:05:11,215 -                                     root -       INFO - Done with target tree creation\n",
      "2022-06-21 16:05:30,281 -                laserfarm.data_processing -       INFO - ... normalization completed.\n",
      "2022-06-21 16:05:30,283 -                laserfarm.data_processing -       INFO - Filtering point-cloud data\n",
      "2022-06-21 16:05:31,130 -                laserfarm.data_processing -       INFO - Exporting environment point-cloud ...\n",
      "2022-06-21 16:05:31,131 -                laserfarm.data_processing -       INFO - ... exporting /tmp/tile_278_391_output/tile_278_391.laz\n",
      "2022-06-21 16:05:33,090 -                laserfarm.data_processing -       INFO - ... exporting completed.\n",
      "2022-06-21 16:05:33,091 -                laserfarm.data_processing -       INFO - Clearing cached KDTrees ...\n",
      "2022-06-21 16:05:33,094 -           laserfarm.pipeline_remote_data -       INFO - Pushing to WebDAV /webdav/norm ...\n",
      "2022-06-21 16:05:36,849 -           laserfarm.pipeline_remote_data -       INFO - ... pushing completed.\n"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "import copy\n",
    "\n",
    "tiles\n",
    "\n",
    "remote_path_norm = str(conf_remote_path_norm)\n",
    "\n",
    "normalization_input = {\n",
    "    'setup_local_fs': {'tmp_folder': conf_local_tmp.as_posix()},\n",
    "    'pullremote': conf_remote_path_retiled.as_posix(),\n",
    "    'load': {'attributes': 'all'},\n",
    "    # Filter out artifically high points - give overflow error when writing\n",
    "    'apply_filter': {'filter_type':'select_below',\n",
    "                     'attribute': 'z',\n",
    "                     'threshold': 10000.},  # remove non-physically heigh points\n",
    "    'normalize': 1,\n",
    "    'clear_cache' : {},\n",
    "    'pushremote': conf_remote_path_norm.as_posix(),\n",
    "}\n",
    "\n",
    "# write input dictionary to JSON file\n",
    "with open('normalize.json', 'w') as f:\n",
    "    json.dump(normalization_input, f)\n",
    "    \n",
    "\n",
    "# add pipeline list to macro-pipeline object and set the corresponding labels\n",
    "tile = tiles\n",
    "# for tile in tiles:\n",
    "normalization_input_ = copy.deepcopy(normalization_input)\n",
    "normalization_input_['export_point_cloud'] = {'filename': '{}.laz'.format(tile),'overwrite': True}\n",
    "dp = DataProcessing(tile, label=tile).config(normalization_input_).setup_webdav_client(conf_wd_opts)\n",
    "dp.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5619aac-f36a-4509-8d92-258e2da56122",
   "metadata": {},
   "source": [
    "## Fetching normalized files (tiles) from remote WebDAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b4e0ec1-e139-494b-9c76-b8c32cf0e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch norm Tiles\n",
    "remote_path_norm\n",
    "norm_tiles = [t.strip('/') for t in list_remote(get_wdclient(conf_wd_opts), conf_remote_path_norm.as_posix())\n",
    "         if fnmatch.fnmatch(t, 'tile_*_*.laz')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c1c49-e148-4809-8a99-b962e8e5b490",
   "metadata": {},
   "source": [
    "## Extract features - extract defined features from normalized tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52636f93-5279-45a8-9f66-460e300f47c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 16:05:52,411 -           laserfarm.pipeline_remote_data -       INFO - Input dir set to /tmp/tile_287_378_input\n",
      "2022-06-21 16:05:52,412 -           laserfarm.pipeline_remote_data -       INFO - Output dir set to /tmp/tile_287_378_output\n",
      "2022-06-21 16:05:52,413 -           laserfarm.pipeline_remote_data -       INFO - Pulling from WebDAV /webdav/norm/tile_287_378.laz ...\n",
      "2022-06-21 16:05:53,673 -           laserfarm.pipeline_remote_data -       INFO - ... pulling completed.\n",
      "2022-06-21 16:05:53,675 -                laserfarm.data_processing -       INFO - Loading point cloud data ...\n",
      "2022-06-21 16:05:53,675 -                laserfarm.data_processing -       INFO - ... loading /tmp/tile_287_378_input/tile_287_378.laz\n",
      "2022-06-21 16:05:53,781 -                laserfarm.data_processing -       INFO - ... loading completed.\n",
      "2022-06-21 16:05:53,782 -                laserfarm.data_processing -       INFO - Normalizing point-cloud heights ...\n",
      "2022-06-21 16:05:53,821 -                                     root -       INFO - Cylinder size in Bytes: 82802329.25213549\n",
      "2022-06-21 16:05:53,822 -                                     root -       INFO - Memory size in Bytes: 16819240960\n",
      "2022-06-21 16:05:53,823 -                                     root -       INFO - Start tree creation\n",
      "2022-06-21 16:05:53,854 -                                     root -       INFO - Done with env tree creation\n",
      "2022-06-21 16:05:53,857 -                                     root -       INFO - Done with target tree creation\n",
      "2022-06-21 16:05:54,834 -                laserfarm.data_processing -       INFO - ... normalization completed.\n",
      "2022-06-21 16:05:54,836 -                laserfarm.data_processing -       INFO - Filtering point-cloud data\n",
      "2022-06-21 16:05:54,837 -                laserfarm.data_processing -       INFO - Setting up the target grid\n",
      "2022-06-21 16:05:54,838 -                laserfarm.data_processing -       INFO - Checking whether points belong to cell (287,378)\n",
      "2022-06-21 16:05:54,840 -                laserfarm.data_processing -       INFO - Generating target point mesh with 10.0m spacing \n",
      "2022-06-21 16:05:54,843 -                laserfarm.data_processing -       INFO - Building volume of type cell\n",
      "2022-06-21 16:05:54,844 -                laserfarm.data_processing -       INFO - Constructing neighborhoods\n",
      "2022-06-21 16:05:54,846 -                laserfarm.data_processing -       INFO - Starting feature extraction ...\n",
      "2022-06-21 16:05:54,849 -                                     root -       INFO - Cylinder size in Bytes: 6408849013.323179\n",
      "2022-06-21 16:05:54,851 -                                     root -       INFO - Memory size in Bytes: 16819240960\n",
      "2022-06-21 16:05:54,853 -                                     root -       INFO - Start tree creation\n",
      "2022-06-21 16:05:54,854 -                                     root -       INFO - Done with env tree creation\n",
      "2022-06-21 16:05:54,859 -                                     root -       INFO - Done with target tree creation\n",
      "2022-06-21 16:05:54,880 -                                     root -       INFO - Extracting feature(s) \"['perc_95_normalized_height']\"\n",
      "2022-06-21 16:05:54,952 -                                     root -       INFO - Extracting feature(s) \"['perc_95_normalized_height']\" took 0.07 seconds\n",
      "2022-06-21 16:05:54,954 -                laserfarm.data_processing -       INFO - ... feature extraction completed.\n",
      "2022-06-21 16:05:54,957 -                laserfarm.data_processing -       INFO - Exporting target point-cloud ...\n",
      "2022-06-21 16:05:54,959 -                laserfarm.data_processing -       INFO - ... exporting /tmp/tile_287_378_output/perc_95_normalized_height/tile_287_378.ply\n",
      "2022-06-21 16:05:55,078 -                laserfarm.data_processing -       INFO - ... exporting completed.\n",
      "2022-06-21 16:05:55,079 -           laserfarm.pipeline_remote_data -       INFO - Pushing to WebDAV /webdav/targets ...\n",
      "2022-06-21 16:05:57,879 -           laserfarm.pipeline_remote_data -       INFO - ... pushing completed.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m processing\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     50\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m---> 51\u001b[0m send_annotation(start\u001b[38;5;241m=\u001b[39m\u001b[43mstart\u001b[49m,end\u001b[38;5;241m=\u001b[39mend,message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature Extraction 01-06-22\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "features = [param_feature_name]\n",
    "\n",
    "tile_mesh_size = float(param_tile_mesh_size)\n",
    "\n",
    "grid_feature = {\n",
    "    'min_x': float(param_min_x),\n",
    "    'max_x': float(param_max_x),\n",
    "    'min_y': float(param_min_y),\n",
    "    'max_y': float(param_max_y),\n",
    "    'n_tiles_side': int(param_n_tiles_side)\n",
    "}\n",
    "\n",
    "feature_extraction_input = {\n",
    "    'setup_local_fs': {'tmp_folder': conf_local_tmp.as_posix()},\n",
    "    'pullremote': conf_remote_path_norm.as_posix(),\n",
    "    'load': {'attributes': [param_attribute]},\n",
    "    'normalize': 1,\n",
    "    'apply_filter': {\n",
    "        'filter_type': param_filter_type, \n",
    "        'attribute': param_attribute,\n",
    "        'value': [int(param_apply_filter_value)]#ground surface (2), water (9), buildings (6), artificial objects (26), and unclassified (1)\n",
    "    },\n",
    "    'generate_targets': {\n",
    "        'tile_mesh_size' : tile_mesh_size,\n",
    "        'validate' : True,\n",
    "        'validate_precision': float(param_validate_precision),\n",
    "        **grid_feature\n",
    "    },\n",
    "    'extract_features': {\n",
    "        'feature_names': features,\n",
    "        'volume_type': 'cell',\n",
    "        'volume_size': tile_mesh_size\n",
    "    },\n",
    "    'export_targets': {\n",
    "        'attributes': features,\n",
    "        'multi_band_files': False\n",
    "    },\n",
    "    'pushremote': conf_remote_path_targets.as_posix(),\n",
    "#     'cleanlocalfs': {}\n",
    "}    \n",
    "\n",
    "t = norm_tiles\n",
    "# for t in norm_tiles:\n",
    "stem, _ = os.path.splitext(t)\n",
    "idx = [int(el) for el in (stem.split('_')[1:])]\n",
    "processing = DataProcessing(t, tile_index=idx,label=stem).config(feature_extraction_input).setup_webdav_client(conf_wd_opts)\n",
    "processing.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1374ed-5c88-4686-b266-6e7610471059",
   "metadata": {},
   "source": [
    "## GeoTIFF export - generate GeoTIFF raster layer a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63ae4e5f-1a8a-4a50-a221-9302053e8092",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m     28\u001b[0m feature \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m---> 30\u001b[0m remote_path_geotiffs \u001b[38;5;241m=\u001b[39m \u001b[43mparam_remote_path_ahn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeotiffs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# setup input dictionary to configure the GeoTIFF export pipeline\u001b[39;00m\n\u001b[1;32m     33\u001b[0m geotiff_export_input \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetup_local_fs\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp_folder\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_local_tmp\u001b[38;5;241m.\u001b[39mas_posix()},\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpullremote\u001b[39m\u001b[38;5;124m'\u001b[39m: conf_remote_path_targets\u001b[38;5;241m.\u001b[39mas_posix(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleanlocalfs\u001b[39m\u001b[38;5;124m'\u001b[39m: {}   \n\u001b[1;32m     41\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'parent'"
     ]
    }
   ],
   "source": [
    "# GeoTIFF Export\n",
    "feature = features\n",
    "\n",
    "remote_path_geotiffs = pathlib.Path(param_remote_path_ahn).parent / 'geotiffs'\n",
    "\n",
    "# setup input dictionary to configure the GeoTIFF export pipeline\n",
    "geotiff_export_input = {\n",
    "    'setup_local_fs': {'tmp_folder': conf_local_tmp.as_posix()},\n",
    "    'pullremote': conf_remote_path_targets.as_posix(),\n",
    "    'parse_point_cloud': {},\n",
    "    'data_split': {'xSub': 1, 'ySub': 1},\n",
    "    'create_subregion_geotiffs': {'output_handle': 'geotiff'},\n",
    "    'pushremote': remote_path_geotiffs.as_posix(),\n",
    "    'cleanlocalfs': {}   \n",
    "}\n",
    "\n",
    "writer = GeotiffWriter(input_dir=param_feature_name, bands=param_feature_name,label=param_feature_name).config(geotiff_export_input).setup_webdav_client(conf_wd_opts)\n",
    "writer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346152b3-b2da-4be7-8137-e9ba2f8f6075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/webdav/geotiffs\n"
     ]
    }
   ],
   "source": [
    "print(remote_path_geotiffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c1c23-bb5d-4763-96bb-65ca815909fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d29b2c-e684-49be-83ec-51fb56bf1a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
