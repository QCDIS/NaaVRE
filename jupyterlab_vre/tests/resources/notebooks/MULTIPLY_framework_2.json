{"save": false, "cell_index": 2, "notebook": {"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "code", "source": "# # Errors\n# ## patched\n# * '/datastore' directory not found -> uploaded data directory to user directory and modified reference:\n#     \"working_dir = f'/home/jovyan/data/working_dirs/{dir_name}'\n\n\n# ## unresolved\n# * cannot import name 'AwsTileRequest' from 'sentinelhub'\n#     * conda install sentinelhub[aws]", "metadata": {"tags": []}, "execution_count": 1, "outputs": [], "id": "5261bfc9-e8e0-4f22-965e-90289054ba3d"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "6eef1f01-fa99-42ad-b25e-763b8774617f"}, {"cell_type": "markdown", "source": "# 3 Setup\nAll the code for the individual modules are is located at https://github.com/multiply-org/. This can be used to setup the MULTIPLY framework on your own computing infrastructure. At present however no deployment setup (in the form of windows-setup-executables, or anaconda package\u2019s) exist. While this is planned further intolater in the project, the focus at this stage is on testing the individual components themselves. Please let us know if you would prefer to install the software yourself on a dedicated computational framework, so that we can investigate how to facilitate this for you. \nIn order to facilitate the testing of the framework itself, we have setup this Virtual Machine on Google Compute Engine, for testing purposes. ", "metadata": {}, "id": "fde27e6d-7166-4bed-b96e-df790ce0d056"}, {"cell_type": "markdown", "source": "## 3.1 Parameters\nHere you can actually set the parameters for the run. \n", "metadata": {}, "id": "ef485e4e-fb1a-40f3-92e8-7629b3876f4b"}, {"cell_type": "markdown", "source": "### Define working_directory", "metadata": {}, "id": "bca58842-f83d-4d65-a433-5a85ab4e2659"}, {"cell_type": "code", "source": "working_directory_name = 'OVP_test_pynb39_20220717'", "metadata": {}, "execution_count": null, "outputs": [], "id": "378d5f60-76f7-4688-bbe3-4c6b887bc718"}, {"cell_type": "markdown", "source": "### 3.1.1 Define region of Interest\n* **roi**: A region of interest, given as a Polygon in WKT format. You can use this tool ( https://arthur-e.github.io/Wicket/sandbox-gmaps3.html ) to easily get definitions of the regions you are interested in in WGS84 coordinates.\n* **roi_grid**: The EPSG-code of the spatial reference system in which the roi is given. If it is set to 'none', it is assumed that the roi is given in WGS84 coordinates.\n* **destination_grid**: The EPSG-code of the spatial reference system in which the output shall be given. If it is set to 'none', the platform will attempt to derive it from the roi_grid.\n* **spatial_resolution**: The resolution the output data is supposed to have, must be a non-negative integer number. The resolution is given in meters and is the same for both dimensions.", "metadata": {}, "id": "71a2076e-e198-434e-a688-e1e46839d9d7"}, {"cell_type": "code", "source": "roi = 'POLYGON(( 5.695 52.26,  5.695 52.25,  5.680 52.25,  5.680 52.26,  5.695 52.26 ))' #Speulderbos. SIAC not working on this area possibly due to tiling\nroi = 'POLYGON ((5.163574 52.382529, 5.163574 52.529813, 5.493164 52.529813, 5.493164 52.382529, 5.163574 52.382529))' #OVP. Correct in MUI version\nroi_grid = 'EPSG:4326'                            # WGS84\ndestination_grid = 'EPSG:4326'                   # WGS84\nspatial_resolution = 20 # in m", "metadata": {}, "execution_count": null, "outputs": [], "id": "e79588c5-4de5-4a30-acd9-c2f2897b0d89"}, {"cell_type": "markdown", "source": "### 3.1.2 Define temporal frequency and period\n* **start_time**: The start date of the period you are interested in, must be given in the format 'Year-Month-Day' as below.\n* **end_time**: The end date of the period you are interested in, must be given in the format 'Year-Month-Day' as below.\n* **time_step**: The temporal resolution the output is supposed to have. Data will be aggregated over the period denoted by this parameter. Must be a non-negative integer value. The unit is days.", "metadata": {}, "id": "21752f6e-45cb-4a26-8200-b35362758d87"}, {"cell_type": "code", "source": "start_time_as_string = '2019-04-16'\nstop_time_as_string = '2019-04-17'\n\nstart_time_as_string = '2018-04-16'\nstop_time_as_string = '2018-04-20'\n\nstart_time_as_string = '2008-04-16'\nstop_time_as_string = '2008-04-20'\n\ntime_step = 5 # in days\n", "metadata": {}, "execution_count": null, "outputs": [], "id": "d0bea94a-a888-46d9-b071-9db26378e244"}, {"cell_type": "markdown", "source": "### 3.1.2 Variables \n* **variables**: The list of the biophysical variables that shall be derived. Please do not change this list, as the underlying forward model requires all of them. The parameters are as follows:\n  * **n**: Structural parameter\n  * **cab**: Leaf Chlorophyll Content, given in ug/cm\u00b2\n  * **car**: Leaf Carotonoid Content, given in ug/cm\u00b2\n  * **cb**: Leaf senescent material\n  * **cw**: Leaf Water Content, given in cm\n  * **cdm**: Leaf Dry Mass, given in g/cm\u00b2\n  * **lai**: Effective Leaf Area Index, given in m\u00b2/m\u00b2\n  * **ala**: Average Leaf Angle, given in degrees\n  * **bsoil**: Soil Brightness Parameter\n  * **psoil**: Soil Wetness Parameter\n* **file_mask**: A file that can be used to explicitly state the region you are interested in. You can also use it to mask out single pixels within this region. If this is not 'none', the aforementioned parameters roi_grid, spatial_resolution, and destination_grid are not used.\n\n**HINT**: The platform will perform faster the smaller your roi and the larger the spatial resolution is.", "metadata": {}, "id": "d25cef17-b8d1-4374-9374-0a7466fd48ce"}, {"cell_type": "code", "source": "variables = {'n', 'cab', 'car', 'cb', 'cw', 'cdm', 'lai', 'ala', 'bsoil', 'psoil'}\nfile_mask = None", "metadata": {}, "execution_count": null, "outputs": [], "id": "9ec24c8f-1951-496d-8f95-b8b197b53198"}, {"cell_type": "markdown", "source": "## 3.2 Load internal packages and auxiliary methods", "metadata": {}, "id": "1bcdd071-a05e-4374-a92e-3bb62435a4e6"}, {"cell_type": "code", "source": "from multiply_data_access import DataAccessComponent\nfrom vm_support.utils import create_config_file, set_permissions\nfrom vm_support.sym_linker import create_sym_links\nimport datetime\nimport glob", "metadata": {}, "execution_count": null, "outputs": [], "id": "508b4557-5283-4283-bcdf-8ce0d21198bc"}, {"cell_type": "markdown", "source": "## 3.2 Defining the additional interfaces", "metadata": {}, "id": "d49a88bc-0e20-4d9f-88ef-9acd1bfccdda"}, {"cell_type": "code", "source": "def get_static_data(data_access_component: DataAccessComponent, roi: str, roi_grid: str, start_time: str,\n                    stop_time: str, emulation_directory: str, dem_directory: str):\n    create_dir(emulation_directory)\n    create_dir(dem_directory)\n\n    rg = roi_grid\n    if roi_grid == 'none':\n        rg = None\n\n    print('Retrieving emulators ...')\n    emu_urls = data_access_component.get_data_urls(roi, start_time, stop_time, 'ISO_MSI_A_EMU,ISO_MSI_B_EMU', rg)\n    set_permissions(emu_urls)\n    create_sym_links(emu_urls, emulation_directory)\n    \n    print('Retrieving DEM ...')\n    # import pdb\n    # pdb.set_trace()\n    dem_urls = data_access_component.get_data_urls(roi, start_time, stop_time, 'Aster_DEM', rg)\n    set_permissions(dem_urls)\n    create_sym_links(dem_urls, dem_directory)\n    print('Done retrieving static data')\n", "metadata": {}, "execution_count": null, "outputs": [], "id": "0c6d105b-0a4a-45dc-b71b-601bb6d9694c"}, {"cell_type": "code", "source": "def create_dir(dir):\n    try:\n        if not os.path.exists(dir):\n            os.makedirs(dir)\n    except:\n        print(dir)\n    return", "metadata": {}, "execution_count": null, "outputs": [], "id": "a2da1d1b-9a13-4c14-86ea-980a30d158e2"}, {"cell_type": "code", "source": "def get_dynamic_data(data_access_component: DataAccessComponent, roi: str, roi_grid: str, start_time: str,\n                     stop_time: str, modis_directory: str, cams_tiff_directory: str, s2_l1c_directory: str):\n    create_dir(modis_directory)\n    create_dir(cams_tiff_directory)\n    create_dir(s2_l1c_directory)\n\n    modis_delta = datetime.timedelta(days=16)\n    start = datetime.datetime.strptime(start_time, '%Y-%m-%d')\n    modis_start = start - modis_delta\n    modis_start_time = datetime.datetime.strftime(modis_start, '%Y-%m-%d')\n    end = datetime.datetime.strptime(stop_time, '%Y-%m-%d')\n    modis_end = end + modis_delta\n    modis_end_time = datetime.datetime.strftime(modis_end, '%Y-%m-%d')\n    \n    rg = roi_grid\n    if roi_grid == 'none':\n        rg = None\n\n    import pdb\n    pdb.set_trace()\n    print('Retrieving MODIS BRDF descriptors ...')\n    modis_urls = data_access_component.get_data_urls(roi, modis_start_time, modis_end_time, 'MCD43A1.006', rg)\n    set_permissions(modis_urls)\n    create_sym_links(modis_urls, modis_directory)\n    \n    # print('Retrieving CAMS data ...')\n    # cams_urls = data_access_component.get_data_urls(roi, start_time, stop_time, 'CAMS_TIFF', rg)\n    # set_permissions(cams_urls)\n    # create_sym_links(cams_urls, cams_tiff_directory)\n    # print('Retrieving S2 L1C data ...')\n    # s2_urls = data_access_component.get_data_urls(roi, start_time, stop_time, 'AWS_S2_L1C, S2_L1C', rg)\n    # set_permissions(s2_urls)\n    # create_sym_links(s2_urls, s2_l1c_directory)\n    print('Done retrieving dynamic data')", "metadata": {}, "execution_count": null, "outputs": [], "id": "ba57ab18-1162-474d-9c4d-c8606349adbf"}, {"cell_type": "code", "source": "import os\nimport shutil\ndef get_working_dir(dir_name: str) -> str:\n    working_dir = f'/datastore/working_dirs/{dir_name}'\n    working_dir = f'/home/jovyan/data/working_dirs/{dir_name}'\n    if os.path.exists(working_dir):\n        shutil.rmtree(working_dir)\n    os.makedirs(working_dir)\n    return working_dir", "metadata": {}, "execution_count": null, "outputs": [], "id": "244ba9f2-5f76-46bc-ae4e-21dd93b3538d"}, {"cell_type": "markdown", "source": "# 4 Running MULTIPLY\nBelow the actual code is provided for running the MULTIPLY framework.\nWe start with setting earth data authentication. This is required to download the MODIS brdf descriptors which are required for the atmospheric correction of the Sentinel-2 data. You can get credentials when you register at https://urs.earthdata.nasa.gov/profile . Registration and use is free of cost. If you do not register, you can only use the MODIS data which has been downloaded in previous runs of the notebook by other users.\nAlso you will need to set up the data stores so that the data access component is working correctly and finds the pre-configured data stores. Both steps only need to be performed once.", "metadata": {}, "id": "39627de6-dcf3-4985-ac60-943600ff9596"}, {"cell_type": "markdown", "source": "### 4.1 Creating working directory\nFor this notebook, you will operate in your own working directory. All data you use will be copied here, all output will be written here.", "metadata": {}, "id": "29af16b3-8ff2-4913-96ea-85ebd0edddf0"}, {"cell_type": "code", "source": "start_time_as_datetime = datetime.datetime.strptime(start_time_as_string, '%Y-%m-%d')\nstop_time_as_datetime = datetime.datetime.strptime(stop_time_as_string, '%Y-%m-%d')\n\ntime_step_as_time_delta = datetime.timedelta(days=time_step)", "metadata": {}, "execution_count": null, "outputs": [], "id": "bde63a7c-6016-4800-bb50-61d22329c472"}, {"cell_type": "code", "source": "# Setup clean working directory\nname = working_directory_name\nworking_dir = get_working_dir(name)\n\n# use previous (non-empty) working directory\n# working_dir = '/Data/test_user_16/' + name\n# working_dir = '/datastore/working_dirs/' + name", "metadata": {}, "execution_count": null, "outputs": [], "id": "c8616ce4-e5ec-4d8b-aa66-80e1a5763e60"}, {"cell_type": "code", "source": "print('Working directory is {}'.format(working_dir))\n\npriors_directory = '{}/priors'.format(working_dir)\nhres_state_dir = '{}/hresstate'.format(working_dir)\nmodis_directory = '{}/modis'.format(working_dir)\nstate_directory = '{}/state'.format(working_dir)\ncams_directory = '{}/cams'.format(working_dir)\ns2_l1c_directory = '{}/s2'.format(working_dir)\nsdrs_directory = '{}/sdrs'.format(working_dir)\nbiophys_output = '{}/biophys'.format(working_dir)\nemulators_directory = '{}/emulators'.format(working_dir)\ndem_directory = '{}/dem'.format(working_dir)\n\nprint(working_dir)", "metadata": {}, "execution_count": null, "outputs": [], "id": "a0c23b62-f5dc-485e-8029-25bdefe689a5"}, {"cell_type": "markdown", "source": "## 5.2 Acquire Data\nWe differentiate between two types of data here: Dynamic and static, meaning: Data which are valid for a certain period of time and data which is valid permanently. The latter is the elevation data of the Digital Elevation Model and the Emulators required for the Atmospheric Correction. We put them in their designated folders before we start our loop through time.", "metadata": {}, "id": "d33209e9-4e5f-44f1-80e7-9e9c0b192c9a"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "463dabcc-3973-4cfe-be09-4d298a9e2478"}, {"cell_type": "code", "source": "# import pdb\n# pdb.runcall(DataAccessComponent)\n\ndata_access_component = DataAccessComponent()", "metadata": {}, "execution_count": null, "outputs": [], "id": "ef25ee51-17b7-4599-ac5c-d15c9b9c64bb"}, {"cell_type": "markdown", "source": "### 5.2.1 Download Static Data", "metadata": {}, "id": "3608951e-7f55-4af4-a0db-fe94cc40cf44"}, {"cell_type": "code", "source": "get_static_data(data_access_component=data_access_component, roi=roi,\n                start_time=start_time_as_string, stop_time=stop_time_as_string, \n          emulation_directory=emulators_directory, dem_directory=dem_directory, roi_grid=roi_grid)", "metadata": {}, "execution_count": null, "outputs": [], "id": "77abe6fb-1862-4628-82d5-0a35f25551c1"}, {"cell_type": "markdown", "source": "These stepping of time works as follows: Dedicated directories are set up for the MODIS, CAMS, and S2 data. These data are retrieved and put into these directories. After that, pre-processing will take place either on the whole S2 image or on the region of interest. If it has been performed on the whole region, the result will be permanently saved. Next, priors will be derived for every variable and every day within the current period. Having gathered all these, the inference can finally begin. The state of the inference engine is saved and considered during the next iteration.", "metadata": {}, "id": "2c51025a-1d95-4cf5-98d6-ea4285c6d453"}, {"cell_type": "markdown", "source": "### 5.2.2 Download Dynamic Data\nFirst for explanation, we will perform the inference over a single timestep. During this, we will show all the results to indicate the flow of the processings. ", "metadata": {}, "id": "53d3e2f2-a2d3-4894-bec6-4b41f54d872d"}, {"cell_type": "code", "source": "# Setting up\ncursor = start_time_as_datetime\nprevious_inference_state = None #'none'\nupdated_inference_state = 'none'\none_day_step = datetime.timedelta(days=1)\npreprocess_only_region_of_interest = True\n\ndate_as_string = datetime.datetime.strftime(cursor, '%Y-%m-%d')\n\ncursor += time_step_as_time_delta\ncursor -= one_day_step\nif cursor > stop_time_as_datetime:\n    cursor = stop_time_as_datetime\nnext_date_as_string = datetime.datetime.strftime(cursor, '%Y-%m-%d')\ncursor += one_day_step\ncursor_as_string = datetime.datetime.strftime(cursor, '%Y-%m-%d')\n\nmodis_directory_for_date = '{}/{}'.format(modis_directory, date_as_string)\ncams_directory_for_date = '{}/{}'.format(cams_directory, date_as_string)\ns2_l1c_directory_for_date = '{}/{}'.format(s2_l1c_directory, date_as_string)\nsdrs_directory_for_date = '{}/{}'.format(sdrs_directory, date_as_string)\npriors_directory_for_date = '{}/{}/'.format(priors_directory, date_as_string)\n", "metadata": {}, "execution_count": null, "outputs": [], "id": "ce9ad18c-a5c9-4e1a-a9cb-b1944065eeae"}, {"cell_type": "code", "source": "get_dynamic_data(data_access_component, roi, roi_grid, date_as_string, next_date_as_string,\n                 modis_directory_for_date, cams_directory_for_date, s2_l1c_directory_for_date)", "metadata": {}, "execution_count": null, "outputs": [], "id": "2bd997ce-9fdf-4df5-871c-6dfd739fe0b0"}, {"cell_type": "code", "source": "break /tmp/data-access/multiply_data_access/data_access_component.py:204\n# break /tmp/data-access/multiply_data_access/lpdaac_data_access.py:109\n\nbreak /tmp/data-access/multiply_data_access/lpdaac_data_access.py:", "metadata": {}, "execution_count": null, "outputs": [], "id": "580198e9-e184-450f-8e36-2d2925ee43d3"}, {"cell_type": "code", "source": "http://e4ftl01.cr.usgs.gov//MOTA/MCD43A1.006/2008.03.31/\n\nhttps://e4ftl01.cr.usgs.gov//MOTA/MCD43A1.006/2018.03.31/", "metadata": {}, "execution_count": null, "outputs": [], "id": "60e61225-ca62-4420-8f21-d352ba256ccc"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "a14e8bfd-9714-4324-a589-76039f80bd41"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "9a1da270-dbd9-40a9-95ff-50d5b0d42b3c"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "47066f60-7631-4b77-a70e-8bfd47bcee88"}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": [], "id": "a0e470df-6307-4303-bf9e-cb4408b24680"}]}}
